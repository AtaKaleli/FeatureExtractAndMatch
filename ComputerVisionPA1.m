clear all; clc;

% first of all, the compilation process takes a bit time
% (for my computer,it takes 30seconds).

%I chose a picture of a dog and a cat
image1=im2gray(imread("reference1.jpg"));
image2=im2gray(imread("reference2.jpg"));

%I saved them in a folder named Dataset
imwrite(image1,"Dataset\image1.jpg");
imwrite(image2,"Dataset\image2.jpg");

%I scaled my reference images with factor of 2 and 5
%I used imresize build in function to scale them
transformed1_S2=imresize(image1,2,"nearest");
transformed1_S5=imresize(image1,5,"nearest");
transformed2_S2=imresize(image2,2,"nearest");
transformed2_S5=imresize(image2,5,"nearest");

%I rotated my reference images with degree of 30 and 130
%I used imrotate build in function to rotate them
transformed1_R30=imrotate(image1,30,"nearest");
transformed1_R130=imrotate(image1,130,"nearest");
transformed2_R30=imrotate(image2,30,"nearest");
transformed2_R130=imrotate(image2,130,"nearest");

%After creating transformed images, I saved them into my Dataset folder
imwrite(transformed1_S2,"Dataset\transformed1_S2.jpg");
imwrite(transformed1_S5,"Dataset\transformed1_S5.jpg");
imwrite(transformed2_S2,"Dataset\transformed2_S2.jpg");
imwrite(transformed2_S5,"Dataset\transformed2_S5.jpg");
imwrite(transformed1_R30,"Dataset\transformed1_R30.jpg");
imwrite(transformed1_R130,"Dataset\transformed1_R130.jpg");
imwrite(transformed2_R30,"Dataset\transformed2_R30.jpg");
imwrite(transformed2_R130,"Dataset\transformed2_R130.jpg");


%here, I assign folderName as my name of the folder, and use it as an input
%of FeatureExtractor function.

folderName = "Dataset";

%The FeatureExtractor function takes folderName as an input, and generates
%features and valid points of the images in my folder. In this function, as
%I have several images in my folder, I saved these features and validPoints
%as 10x1 "cells". In this way, every cell contains the properties of an
%image from 1 to 10.

[features,valid_points]=FeatureExtractor(folderName);


%The FeatureMatcher function takes two images that I have compared with ,and
%the features and valid_points of these images generated by
%FeatureExtractor function as an input. After taking these inputs, this
%function matches the features of two images, and show them. I also display
%the top100 distances of every one of the comparison in the same figure.
%So, I have displayed total of 8 figures, as I have called FeatureMatcher
%eight times.

%The comparison between the first reference image and four transformation of
%it
FeatureMatcher(image1,transformed1_S2,features{1},features{5},valid_points{1},valid_points{5});
FeatureMatcher(image1,transformed1_S5,features{1},features{6},valid_points{1},valid_points{6});
FeatureMatcher(image1,transformed1_R30,features{1},features{4},valid_points{1},valid_points{4});
FeatureMatcher(image1,transformed1_R130,features{1},features{3},valid_points{1},valid_points{3});

%The comparison between the second reference image and four transformation of
%it
FeatureMatcher(image2,transformed2_S2,features{2},features{9},valid_points{2},valid_points{9});
FeatureMatcher(image2,transformed2_S5,features{2},features{10},valid_points{2},valid_points{10});
FeatureMatcher(image2,transformed2_R30,features{2},features{8},valid_points{2},valid_points{8});
FeatureMatcher(image2,transformed2_R130,features{2},features{7},valid_points{2},valid_points{7});




%% Question 3 part d and e answers

%answer Of d: When I observed the plotting results, I can clearly see that
%there is no any major plotting difference between the scaled images. As
%written in the lecture notes, this is because scale operation is invariant
%to transformations,which means it remains the same despite changes or 
%transformations to the object or scene being observed.

%answer Of e: Same answer as the top. As rotation operation is invariant
%to transformations, there is no effect on angle of the rotation on the
%matching distances.











 
